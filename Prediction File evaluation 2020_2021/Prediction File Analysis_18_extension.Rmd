---
title: "Prediction File Simulations, PY 2019"
output: html_document
fig_caption: yes
---


```{r setup, include=FALSE}
rm(list = ls())
library(dplyr)
library(readxl)
library(tidyr)
library(stringr)
library(readr)
library(lubridate)
library(gmodels)
library(kableExtra)
library(scales)
library(glue)
library(extrafont)
loadfonts(device = "win", quiet = TRUE)
library(ggplot2)


## R Markdown


```

#### This file included workshop analysis of the accuracy of PY 2019 Q1 - PY 2019 Q4 quarterly prediction files. This is in preparation to deliver a memo to CMS which assesses how well the prediction files predict ACO performance categories and savings and losses (measured within this analysis as Total Benchmark Minus Assigned Beneficiary Expenditures).


---

```{r ,echo=FALSE,echo=FALSE, message=FALSE, fig.align='center'}


Finperf = read_excel("Z:\\finance\\prediction file\\2019 simulation\\Extension\\PY18 Financial Reconciliation Management Report.xlsx", sheet = "PY 2018 Fin Perf Table", skip=1) %>% 
  select(`ACO ID`,
         `PY 2018 Track`,
         actual_bench_min_exp = `Total Benchmark Minus Assigned Beneficiary Expenditures`,
         actual_category =`PY 2018 Performance Category`,
         `Current Agreement Start Date`,
         actual_exp = `Total Assigned Beneficiary Expenditures`,
         actual_by_exp = `Total Benchmark Expenditures`,
         actual_pys = `Total Person Years`,
         actual_mean_bnch_exp = `Updated Benchmark`,
         acutal_mean_assg_exp = `Per Capita Expenditures`
         
) %>% 
  rename(ACO_ID = `ACO ID`) %>% 
  mutate(`PY 2018 Assignment Methodology` = ifelse(`PY 2018 Track` %in% c("3", "1+"),"Prospective", "Retrospective"))

Finperf$actual_category[Finperf$actual_category == "Shared savings"] = "Shared Savings"
Finperf$actual_category[Finperf$actual_category == "Negative outside corridor"] = "Negative outside Corridor"



Extract_funtion = function(path, sheet, Quarter){
  read_excel(path, sheet=sheet, skip=3) %>% 
  select(ACO_ID, 
         `Predicted Performance Category`,
         predicted_bench_min_exp = `Total Benchmark Minus Assigned Beneficiary Expenditures`, 
         predicted_bnch_exp = `Total Benchmark expenditures`, 
         predicted_assg_exp = `Total Assigned Beneficiary Expenditures`, 
         predicted_perf_payment = `Shared Savings (Sharing Rate * Total Savings)`, 
         predicted_losses = `Shared Losses (Loss Rate * Total Loss)`,
         predicted_mean_bnch_exp = 35,
         predicted_mean_assg_exp = 40,
         predicted_pys = 26,
         `Second Agreement Start Date`) %>% 
  rename(prediction = `Predicted Performance Category`) %>% inner_join(Finperf,by="ACO_ID") %>% 
  replace_na(list(actual_losses = 0))  %>% 
  mutate(difference_bench_min_exp = (actual_bench_min_exp - predicted_bench_min_exp)/1E6,
         Quarter = Quarter,
         PY18_Benchmark_Methodology = ifelse(`Second Agreement Start Date`=="N/A", 1,
                                                   ifelse(`Second Agreement Start Date` == "42370", 2,3
                                                          )),
         pred_cat_direction = ifelse(prediction %in% c("Shared Savings", "Positive w/in corridor"),"Positive","Negative"),
         actual_cat_direction = ifelse(actual_category %in% c("Shared Savings", "Positive w/in corridor"),"Positive","Negative")) %>% 
    select(-`Second Agreement Start Date`)
  
}

Q1 = Extract_funtion("Z:\\finance\\prediction file\\2019 simulation\\Extension\\Predicting ACO Performance Results_Q4PY2018.xlsx", "2018 Q1 Pred Calc (with Reg HB)", "Q1")
Q2 = Extract_funtion("Z:\\finance\\prediction file\\2019 simulation\\Extension\\Predicting ACO Performance Results_Q4PY2018.xlsx", "2018 Q2 Pred Calc (with Reg HB)", "Q2")
Q3 = Extract_funtion("Z:\\finance\\prediction file\\2019 simulation\\Extension\\Predicting ACO Performance Results_Q4PY2018.xlsx", "2018 Q3 Pred Calc (with Reg HB)", "Q3")
Q4 = Extract_funtion("Z:\\finance\\prediction file\\2019 simulation\\Extension\\Predicting ACO Performance Results_Q4PY2018.xlsx", "2018 Q4 Pred Calc (with Reg HB)", "Q4")

assignment_simulation = Extract_funtion("Z:\\finance\\prediction file\\2019 simulation\\Extension\\Predicting ACO Performance Results_Q4PY2018_assignment_simulation.xlsx", "2018 Q4 Pred Calc (with Reg HB)", "Assg. Sim")
exp_simulation = Extract_funtion("Z:\\finance\\prediction file\\2019 simulation\\Extension\\Predicting ACO Performance Results_Q4PY2018_Mean_exp_simulation.xlsx", "2018 Q4 Pred Calc (with Reg HB)", "Mean Exp. Sim")
upd_bnch_simulation = Extract_funtion("Z:\\finance\\prediction file\\2019 simulation\\Extension\\Predicting ACO Performance Results_Q4PY2018_updated_benchmark_simulation.xlsx", "2018 Q4 Pred Calc (with Reg HB)", "Updated Benchmark Sim")
quality_simulation = Extract_funtion("Z:\\finance\\prediction file\\2019 simulation\\Extension\\Predicting ACO Performance Results_Q4PY2018_quality_simulation.xlsx", "2018 Q4 Pred Calc (with Reg HB)", "Quality Sim")
annual_exp_simulation = Extract_funtion("Z:\\finance\\prediction file\\2019 simulation\\Extension\\Predicting ACO Performance Results_Q4PY2018_annual_expenditures.xlsx", "2018 Q4 Pred Calc (with Reg HB)", "Annual Exp. Sim")
risk_simulation = Extract_funtion("Z:\\finance\\prediction file\\2019 simulation\\Extension\\Predicting ACO Performance Results_Q4PY2018_risk_adjustment.xlsx", "2018 Q4 Pred Calc (with Reg HB)", "Risk Sim")


non_reconciled = read_excel("Z:\\finance\\prediction file\\2019 simulation\\Extension\\Predicting ACO Performance Results_Q4PY2018.xlsx", sheet="2018 Q4 Pred Calc (with Reg HB)", skip=3) %>% filter(!(`ACO_ID` %in% Finperf$ACO_ID)) %>% select(`ACO_ID`)

table(annual_exp_simulation$prediction,annual_exp_simulation$pred_cat_direction)
table(annual_exp_simulation$actual_category,annual_exp_simulation$actual_cat_direction)


```
### Analyzing Accuracy of Quarterly Prediction Files
#### Here we cross-tabulate the predicted and actual performance categories. The primary takeaways are that the accuracy of the Prediction Files increases with each quarter. Simulations to utilize correct assigned beneficiary counts, actual mean beneficiary expenditures, and actual quality scores do not improve accuracy. However, using actual updated benchmarks significantly improves accuracy. The best simulation utilizes updated mean beneficiary expenditures and actual updated benchmarks. 



```{r Create quarterly accuracy graphs,echo=FALSE, message=FALSE, fig.align='center'}


list_tables = list(Q1, Q2, Q3, Q4, assignment_simulation, quality_simulation, annual_exp_simulation,exp_simulation,risk_simulation,upd_bnch_simulation)



simulation_table_func = function(dataset,...){
  
  table = dataset %>% group_by(actual_category,...) %>% mutate(column_total = n()) %>% group_by(actual_category, prediction,...) %>% mutate(count = n()) %>% slice(1) %>% mutate(percentage = paste0("(",scales::percent(count/column_total), ")")) %>%  ungroup()%>% mutate(table_count = paste(as.character(count),percentage ))  %>% select(actual_category, prediction,..., table_count) %>% arrange(desc(actual_category), desc(prediction))
  
  return(table)
}


summary_tables = lapply(list_tables, function(x) simulation_table_func(x))


Output_table = summary_tables %>% purrr::reduce(full_join, by=c("actual_category", "prediction")) 
names(Output_table) = c("actual_category","prediction","Q1", "Q2", "Q3","Q4","Assg. Sim","Quality Sim","Annual Exp. Sim","Mean Exp. Sim","Risk Sim","Updated Benchmark Sim")

join_table = bind_cols(
                      as.data.frame(c(rep(unique(Output_table$actual_category)[1],4),
                        rep(unique(Output_table$actual_category)[2],4),
                        rep(unique(Output_table$actual_category)[3],4),
                        rep(unique(Output_table$actual_category)[4],4))),
                      as.data.frame(rep(c(unique(Output_table$actual_category)[1],
                            unique(Output_table$actual_category)[2],
                            unique(Output_table$actual_category)[3],
                            unique(Output_table$actual_category)[4]),4))
)
names(join_table) = c("actual_category", "prediction")
Output_table = left_join(join_table, Output_table)

openxlsx::write.xlsx(Output_table, "Z:\\finance\\prediction file\\2019 simulation\\Extension\\2018_accuracy.xlsx")


## Make a version of the table that combines positive and negative categories
simulation_table_func_consolidate = function(dataset,...){
  
  table = dataset %>% group_by(actual_cat_direction,...) %>% mutate(column_total = n()) %>% group_by(actual_cat_direction, pred_cat_direction,...) %>% mutate(count = n()) %>% slice(1) %>% mutate(percentage = paste0("(",scales::percent(count/column_total), ")")) %>%  ungroup()%>% mutate(table_count = paste(as.character(count),percentage ))  %>% select(actual_cat_direction, pred_cat_direction,..., table_count) %>% arrange(desc(actual_cat_direction), desc(pred_cat_direction))
  
  return(table)
}


summary_tables = lapply(list_tables, function(x) simulation_table_func_consolidate(x))


Output_table_consolidated = summary_tables %>% purrr::reduce(full_join, by=c("actual_cat_direction", "pred_cat_direction")) 
names(Output_table_consolidated) = c("actual_direction","predicted_direction","Q1", "Q2", "Q3","Q4","Assg. Sim","Quality Sim","Annual Exp. Sim","Mean Exp. Sim","Risk Sim","Updated Benchmark Sim")

openxlsx::write.xlsx(Output_table_consolidated, "Z:\\finance\\prediction file\\2019 simulation\\Extension\\2018_accuracy_consolidated.xlsx")



##### Break out results by assignment category
join_table_assg = bind_rows(Output_table[,c("actual_category","prediction")],
                            Output_table[,c("actual_category","prediction")])
join_table_assg$`PY 2018 Assignment Methodology` =  c(rep(unique(Finperf$`PY 2018 Assignment Methodology`)[1],16),
                                                      rep(unique(Finperf$`PY 2018 Assignment Methodology`)[2],16))


summary_tables_assg = lapply(list_tables, function(x) simulation_table_func(x, `PY 2018 Assignment Methodology`)) %>% purrr::reduce(full_join, by=c("PY 2018 Assignment Methodology", "actual_category", "prediction"))  %>%  full_join(join_table_assg, by=c("actual_category","prediction", "PY 2018 Assignment Methodology")) %>%  arrange(`PY 2018 Assignment Methodology`, desc(actual_category), desc(prediction))



names(summary_tables_assg) = c("actual_category","prediction","PY 2018 Assignment Methodology","Q1", "Q2", "Q3","Q4","Assg. Sim","Quality Sim","Annual Exp. Sim","Mean Exp. Sim","Risk Sim","Updated Benchmark Sim")
write_csv(summary_tables_assg, "Z:\\finance\\prediction file\\2019 simulation\\Extension\\2018_assignment_accuracy.csv")





```


```{r Benchmark Methodology Accuracy breakdown}
join_table_methodology = bind_rows(Output_table[,c("actual_category","prediction")],
                            Output_table[,c("actual_category","prediction")],
                            Output_table[,c("actual_category","prediction")])
join_table_methodology$`PY18_Benchmark_Methodology` = c(rep(unique(Q1$`PY18_Benchmark_Methodology`)[1],16),
                                                   rep(unique(Q1$`PY18_Benchmark_Methodology`)[2],16),
                                                   rep(unique(Q1$`PY18_Benchmark_Methodology`)[3],16))


summary_tables_methodology = lapply(list_tables, function(x) simulation_table_func(x, `PY18_Benchmark_Methodology`)) %>% purrr::reduce(full_join, by=c("actual_category", "prediction", "PY18_Benchmark_Methodology")) %>% full_join(join_table_methodology, by=c("actual_category","prediction", "PY18_Benchmark_Methodology")) %>%  arrange(`PY18_Benchmark_Methodology`, desc(actual_category), desc(prediction))
names(summary_tables_methodology) = c("actual_category", "prediction", "PY18_Benchmark_Methodology","Q1","Q2","Q3","Q4","Assg. Sim","Quality Sim","Annual Exp. Sim","Mean Exp. Sim","Risk Sim","Updated Benchmark Sim")

summary_tables_methodology = purrr::map_df(summary_tables_methodology, function(x) ifelse(is.na(x), "0 (0%)", x))
openxlsx::write.xlsx(summary_tables_methodology, "Z:\\finance\\prediction file\\2019 simulation\\Extension\\2018_methodology_accuracy.xlsx")



```


```{r Additional accuracy predictions}
simulation_table_func_reverse = function(dataset,grouper_1, grouper_2,...){
  
  table = dataset %>% group_by({{grouper_1}},...) %>% mutate(column_total = n()) %>% group_by({{grouper_1}}, {{grouper_2}},...) %>% mutate(count = n()) %>% slice(1) %>% mutate(percentage = paste0("(",scales::percent(count/column_total), ")")) %>%  ungroup()%>% mutate(table_count = paste(as.character(count),percentage ))  %>% select({{grouper_1}}, {{grouper_2}},..., table_count) %>% arrange(desc({{grouper_1}}), desc({{grouper_2}}))
  
  return(table)
}


summary_tables_reverse = lapply(list_tables, function(x) simulation_table_func_reverse(x, prediction, actual_category))

Output_table_reverse = summary_tables_reverse %>% purrr::reduce(full_join, by=c("actual_category", "prediction")) 
names(Output_table_reverse) = c("prediction","actual_category","Q1", "Q2", "Q3","Q4","Assg. Sim","Quality Sim","Annual Exp. Sim","Mean Exp. Sim","Risk Sim","Updated Benchmark Sim")
names(join_table) = c("prediction", "actual_category")
Output_table_reverse = left_join(join_table, Output_table_reverse)
Output_table_reverse = sapply(Output_table_reverse, function(x) ifelse(is.na(x), "0 (0%)",x))

openxlsx::write.xlsx(Output_table_reverse, "Z:\\finance\\prediction file\\2019 simulation\\Extension\\2018_acuracy_reverse.xlsx")

## Make a version of the table that combines positive and negative categories
summary_tables_reverse = lapply(list_tables, function(x) simulation_table_func_reverse(x, pred_cat_direction, actual_cat_direction))


Output_table_reverse_consolidated = summary_tables_reverse %>% purrr::reduce(full_join, by=c("pred_cat_direction", "actual_cat_direction")) 
names(Output_table_reverse_consolidated) = c("predicted_direction","actual_direction","Q1", "Q2", "Q3","Q4","Assg. Sim","Quality Sim","Annual Exp. Sim","Mean Exp. Sim","Risk Sim","Updated Benchmark Sim")

openxlsx::write.xlsx(Output_table_reverse_consolidated, "Z:\\finance\\prediction file\\2019 simulation\\Extension\\2018_accuracy_reverse_consolidated.xlsx")




summary_tables_assg_invert = lapply(list_tables, function(x) simulation_table_func_reverse(x, prediction, actual_category, `PY 2018 Assignment Methodology`)) %>% purrr::reduce(full_join, by=c("PY 2018 Assignment Methodology", "actual_category", "prediction"))  %>%  full_join(join_table_assg, by=c("actual_category","prediction", "PY 2018 Assignment Methodology")) %>%  arrange(`PY 2018 Assignment Methodology`, desc(prediction), desc(actual_category))



names(summary_tables_assg_invert) = c("prediction", "actual_category", "PY 2019 Assignment Methodology","Q1","Q2","Q3","Q4","Assg. Sim","Quality Sim","Annual Exp. Sim","Mean Exp. Sim","Risk Sim","Updated Benchmark Sim")
openxlsx::write.xlsx(summary_tables_assg_invert, "Z:\\finance\\prediction file\\2019 simulation\\Extension\\2018_assignment_accuracy_invert.xlsx")





Overall_accuracy = function(dataset,...){
  
  table = dataset %>%  group_by(...) %>% 
    mutate(total_acos = n()) %>% 
    mutate(correct_prediction = ifelse(prediction==actual_category, 1,0),
           predict_code = ifelse(prediction == "Shared Savings",4,
                                 ifelse(prediction == "Positive w/in corridor",3,
                                 ifelse(prediction == "Negative w/in corridor",2,1))),
           actual_code = ifelse(actual_category == "Shared Savings",4,
                                 ifelse(actual_category == "Positive w/in corridor",3,
                                 ifelse(actual_category == "Negative w/in corridor",2,1))),           
           underprediction = ifelse(predict_code<actual_code,1,0),
           overprediction = ifelse(predict_code>actual_code,1,0)) %>% 
    summarize(
      correct_prediction = mean(correct_prediction),
      overprediction = mean(overprediction),
      underprediction = mean(underprediction),
      count = n()
    )
             

  
  return(table)
}


Overall_accuracy_table = lapply(list_tables, function(x) Overall_accuracy(x)) 
Overall_accuracy_table = do.call("rbind", Overall_accuracy_table)
rownames(Overall_accuracy_table) = c("Q1","Q2","Q3","Q4","Assg. Sim","Quality Sim","Annual Exp. Sim","Mean Exp. Sim","Risk Sim","Updated Benchmark Sim")


openxlsx::write.xlsx(Overall_accuracy_table, "Z:\\finance\\prediction file\\2019 simulation\\Extension\\2018_overall_accuracy.xlsx")


Overall_accuracy_BY = lapply(list_tables, function(x) Overall_accuracy(x, `Current Agreement Start Date`))
Overall_accuracy_BY_table = do.call("rbind", Overall_accuracy_BY)
Overall_accuracy_BY_table$file = rep(c("Q1","Q2","Q3","Q4","Assg. Sim","Quality Sim","Annual Exp. Sim","Mean Exp. Sim","Risk Sim","Updated Benchmark Sim"), each=4)
Overall_accuracy_BY_table$file = factor(Overall_accuracy_BY_table$file, levels = c("Q1","Q2","Q3","Q4","Assg. Sim","Quality Sim","Annual Exp. Sim","Mean Exp. Sim","Risk Sim","Updated Benchmark Sim"))

Overall_accuracy_BY_table = Overall_accuracy_BY_table %>% arrange(`Current Agreement Start Date`, file)

             
openxlsx::write.xlsx(Overall_accuracy_BY_table, "Z:\\finance\\prediction file\\2019 simulation\\Extension\\2018_overall_accuracy_year.xlsx")



```



<br />
<br />

### How well do prediction files estimate aggregate savings/losses
#### Here we produce a table and a graph of the actual minus predicted savings/losses (measured by benchmark expenditures minus assigned beneficiary expenditures). The primary takeaways are that the quarterly prediction files undercounted total savings in Q1 and Q2 and overpredicted savings in Q3 and Q4. Again, simulations utilizing acutal PY 2019 assigned beneficiaries, mean expenditures, and quality scores did little to improve accuracy in predicting total gross savings. Utilizing actual updated benchmarks leads to a significant increase in accuracy in total gross savings predictions. As in the case of predicting performance categories, the top performing simulation combines actual mean expenditures with actual updated benchmarks.



<br />


```{r, echo=FALSE, message=FALSE, fig.align='center', fig.cap='Figure 1: Difference, Actual vs Predicted Benchmark Minus Expenditures', fig.topcaption=TRUE}
cumulative = bind_rows(list_tables)
cumulative$Quarter = factor(cumulative$Quarter, levels = c("Q1","Q2","Q3","Q4","Assg. Sim","Quality Sim","Annual Exp. Sim","Mean Exp. Sim","Risk Sim","Updated Benchmark Sim"))
labels = str_wrap(levels(cumulative$Quarter), width=7)



ggplot(cumulative, aes(x=Quarter, y=difference_bench_min_exp, fill = Quarter)) + 
    geom_boxplot() + ylab("Difference, Actual vs Predicted\nGross Savings") + theme(legend.position="none") +scale_y_continuous(labels=dollar_format(prefix="$", suffix="M")) + xlab("")+  scale_x_discrete(labels = labels) +
  theme(text=element_text(family="Calibri"), axis.text.y = element_text(size=16, colour = "black"),
              axis.text.x = element_text(size=16, colour = "black"),
              axis.title.y = element_text(size=16)) + ggsave("C:\\Users\\lhorvath\\Downloads\\gross savings.png", width=15, height = 6)

```


<br />
<br />


#### We also produce a table of predicted total savings by quarter as a percentage of actual savings, which gives us another way of assessing how Q1 and Q2 prediction files undercounted savings but Q3 and Q4 files overcounted savings. This shows which prediction files (and simulations) undercount and overcount savings.


```{r Total Program Savings, echo=FALSE, message=FALSE, fig.align='center'}

cumulative  %>% group_by(Quarter) %>% 
  summarise(`Total Predicted Benchmark - Expenditures ($M)` = sum(predicted_bench_min_exp)/1E6,
            `Total Actual Benchmark - Expenditures` = sum(actual_bench_min_exp)/1E6,
            `Predicted Benchmark - Expenditures as % of Actual` = scales::percent(`Total Predicted Benchmark - Expenditures ($M)` / `Total Actual Benchmark - Expenditures`, accuracy = .01),
            `Actual Benchmark Expenditures ($M)` = sum(actual_by_exp)/1E6,
            `Predicted Benchmark Expenditures ($M)` = sum(predicted_bnch_exp)/1E6,
            `Predicted Benchmark Expenditures as % of Actual` = scales::percent(`Predicted Benchmark Expenditures ($M)` /  `Actual Benchmark Expenditures ($M)`, accuracy = .01),
            `Actual Assigned Expenditures ($M)` = sum(actual_exp)/1E6,
            `Predicted Assigned Expenditures ($M)` = sum(predicted_assg_exp)/1E6,
            `Predicted Assigned Expenditures as % of Actual` = scales::percent(`Predicted Assigned Expenditures ($M)` /  `Actual Assigned Expenditures ($M)`, accuracy = .01),
            `Predicted PYs as a % of Actual` = scales::percent(sum(predicted_pys) / sum(actual_pys), accuracy = .01)
            ) %>% 
  mutate(`Total Predicted Benchmark - Expenditures ($M)` = comma_format()(`Total Predicted Benchmark - Expenditures ($M)`)) %>% 
  openxlsx::write.xlsx("Z:\\finance\\prediction file\\2019 simulation\\Extension\\2018_gross_savings.xlsx")




##### Break out results by assignment category & year
cumulative  %>% group_by(Quarter, `PY 2018 Assignment Methodology`) %>% 
  summarise(`Total Predicted Benchmark - Expenditures ($M)` = sum(predicted_bench_min_exp)/1E6,
            `Total Actual Benchmark - Expenditures` = sum(actual_bench_min_exp)/1E6,
            `Predicted Benchmark - Expenditures as % of Actual` = scales::percent(`Total Predicted Benchmark - Expenditures ($M)` / `Total Actual Benchmark - Expenditures`, accuracy = .01),
            `Actual Benchmark Expenditures ($M)` = sum(actual_by_exp)/1E6,
            `Predicted Benchmark Expenditures ($M)` = sum(predicted_bnch_exp)/1E6,
            `Predicted Benchmark Expenditures as % of Actual` = scales::percent(`Predicted Benchmark Expenditures ($M)` /  `Actual Benchmark Expenditures ($M)`, accuracy = .01),
            `Actual Assigned Expenditures ($M)` = sum(actual_exp)/1E6,
            `Predicted Assigned Expenditures ($M)` = sum(predicted_assg_exp)/1E6,
            `Predicted Assigned Expenditures as % of Actual` = scales::percent(`Predicted Assigned Expenditures ($M)` /  `Actual Assigned Expenditures ($M)`, accuracy = .01),
            `Predicted PYs as a % of Actual` = scales::percent(sum(predicted_pys) / sum(actual_pys), accuracy = .01)
            ) %>% 
  mutate(`Total Predicted Benchmark - Expenditures ($M)` = comma_format()(`Total Predicted Benchmark - Expenditures ($M)`)) %>% arrange(`PY 2018 Assignment Methodology`, Quarter) %>% 
  openxlsx::write.xlsx("Z:\\finance\\prediction file\\2019 simulation\\Extension\\2018_gross_savings_assignment.xlsx")


cumulative  %>% group_by(Quarter, `Current Agreement Start Date`) %>% 
  summarise(`Total Predicted Benchmark - Expenditures ($M)` = sum(predicted_bench_min_exp)/1E6,
            `Total Actual Benchmark - Expenditures` = sum(actual_bench_min_exp)/1E6,
            `Predicted Benchmark - Expenditures as % of Actual` = scales::percent(`Total Predicted Benchmark - Expenditures ($M)` / `Total Actual Benchmark - Expenditures`, accuracy = .01),
            `Actual Benchmark Expenditures ($M)` = sum(actual_by_exp)/1E6,
            `Predicted Benchmark Expenditures ($M)` = sum(predicted_bnch_exp)/1E6,
            `Predicted Benchmark Expenditures as % of Actual` = scales::percent(`Predicted Benchmark Expenditures ($M)` /  `Actual Benchmark Expenditures ($M)`, accuracy = .01),
            `Actual Assigned Expenditures ($M)` = sum(actual_exp)/1E6,
            `Predicted Assigned Expenditures ($M)` = sum(predicted_assg_exp)/1E6,
            `Predicted Assigned Expenditures as % of Actual` = scales::percent(`Predicted Assigned Expenditures ($M)` /  `Actual Assigned Expenditures ($M)`, accuracy = .01),
            `Predicted PYs as a % of Actual` = scales::percent(sum(predicted_pys) / sum(actual_pys), accuracy = .01)
            ) %>% 
  mutate(`Total Predicted Benchmark - Expenditures ($M)` = comma_format()(`Total Predicted Benchmark - Expenditures ($M)`)) %>% arrange(`Current Agreement Start Date`, Quarter) %>% 
  openxlsx::write.xlsx("Z:\\finance\\prediction file\\2019 simulation\\Extension\\2018_gross_savings_year.xlsx")





```

<br />
<br />

#### Finally, we produce a table that displays calculation of total savings to Medicare (ignoring advanced payment). The actual value for PY 2019 was 832.5$M. Again, the most accurate simulation includes actual updated benchmarks and actual mean beneficiary expenditures.  



```{r Calculate predicted savings to Medicare,echo=FALSE, message=FALSE, fig.align='center'}

cumulative %>% 
  ungroup() %>% 
  group_by(Quarter) %>% 
  summarize(`Total Benchmark Expenditures ($M, All ACOs)` = sum(predicted_bnch_exp) ,
            `Total Assigned Beneficiary Expenditures ($M, All ACOs)` = sum(predicted_assg_exp) ,
            `Total Program Savings ($M, All ACOs)` = `Total Benchmark Expenditures ($M, All ACOs)` - `Total Assigned Beneficiary Expenditures ($M, All ACOs)`,
            `Gross Savings ($M) Generated by ACOs with Savings Outside Minimum Savings Rate` = sum(predicted_bench_min_exp[prediction == "Shared Savings"]) ,
            `Total Performance ($M) Payments to ACOs with Savings Outside Minimum Savings Rate` = sum(predicted_perf_payment) ,
            `Total Losses ($M) Owed by Risk-based ACOs with Losses Outside Minimum Loss Rate` = sum(predicted_losses) * (-1),
            `Total Net Savings (Outlays) to Medicare ($M)` = `Total Program Savings ($M, All ACOs)` - `Total Performance ($M) Payments to ACOs with Savings Outside Minimum Savings Rate` + `Total Losses ($M) Owed by Risk-based ACOs with Losses Outside Minimum Loss Rate`) %>% pivot_longer(!Quarter, names_to = " ") %>% mutate(value = comma_format()(value/1E6)) %>%  pivot_wider(id_cols = ` `, names_from = Quarter, values_from = value) %>% 
    openxlsx::write.xlsx("Z:\\finance\\prediction file\\2019 simulation\\Extension\\2018_net_Medicare_savings.xlsx")



```

